#!/usr/bin/env python
import os
import sys
from age_model import TfProbabilityCnnClassifier
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import traceback

# Note we cant use flow from directory with pipe as it requires tfrecords and no other
# than tf records can be streamed.
prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name = 'training'
training_path = os.path.join(input_path, channel_name)


def train():
    model = TfProbabilityCnnClassifier(input_dim=(128, 128, 3), n_classes=100)

    train_datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        brightness_range=[0.4, 1.5],
        rescale=1. / 255,
    )

    training_dataset = train_datagen.flow_from_directory(
        training_path,
        color_mode="rgb",
        batch_size=32,
        target_size=(128, 128),
        shuffle=True,
        seed=42,
        interpolation="bilinear",
        follow_links=False,
    )

    # if args.test_file is not None:
    #     test_datagen = ImageDataGenerator(
    #         rescale=1. / 255,
    #     )
    #
    #     test_dataset = test_datagen.flow_from_directory(
    #         training_path,
    #         color_mode="rgb",
    #         batch_size=32,
    #         target_size=(128, 128),
    #         shuffle=True,
    #         seed=42,
    #         interpolation="bilinear",
    #         follow_links=False,
    #     )
    # else:
    #     test_dataset = None
    test_dataset = None

    print('fitting model')
    model.fit(training_dataset, epochs=1,
              validation_data=test_dataset, steps_per_epoch=10,
              # validation_steps=args.validation_steps,
              )

    print(model.history.history)

    print('saving model')
    path = os.path.join(model_path, "age_model")
    print(f"saving to {path}")
    model.save_weights(path)
    # All other methods do not work. Saving weights and using load_weights is the easiest.
    # I do wonder if this will work for real time inference as protobuff is the preferred format. Lets see.


if __name__ == '__main__':
    try:
        train()
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
